{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "10977280/11490434 [===========================>..] - ETA: 0s ETA: (50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febd419f5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train_orig, y_train_orig, X_val_orig, y_val_orig, X_test_orig, y_test_orig = load_dataset()\n",
    "print(X_train_orig.shape, y_train_orig.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train_orig[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having a better Understanding about The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 50000\n",
      "number of test examples = 10000\n",
      "X_train shape: (50000, 28, 28)\n",
      "Y_train shape: (50000,)\n",
      "X_val shape: (10000, 28, 28)\n",
      "Y_val shape: (10000,)\n",
      "X_test shape: (10000, 28, 28)\n",
      "Y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train_orig.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test_orig.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train_orig.shape))\n",
    "print (\"Y_train shape: \" + str(y_train_orig.shape))\n",
    "print (\"X_val shape: \" + str(X_val_orig.shape))\n",
    "print (\"Y_val shape: \" + str(y_val_orig.shape))\n",
    "print (\"X_test shape: \" + str(X_test_orig.shape))\n",
    "print (\"Y_test shape: \" + str(y_test_orig.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare the Data set\n",
    "- flatten the X data to get a vector instead of a matrix\n",
    "- fit the label data (y) to have matrix of 10 classes in order to pass it in the softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.1 Flatten the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 50000\n",
      "number of test examples = 10000\n",
      "X_train shape: (50000, 784)\n",
      "X_val shape: (10000, 784)\n",
      "X_test shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1)\n",
    "X_val_flatten = X_val_orig.reshape(X_val_orig.shape[0], -1)\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1)\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_flatten/255.\n",
    "X_test = X_test_flatten/255.\n",
    "X_val = X_val_flatten/255.\n",
    "\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "``size of an image vector (num_px * num_px = 28 * 28 * 1 = 784) # the image we have in a gray scale``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prepare the label data to fit into classes\n",
    "**Note: number of classes, C=10 from 0 till 9**\n",
    "\n",
    "\n",
    "As we can see from the data.\n",
    "The elements in the label vector y have values go from 0 to 9.\n",
    "Which refer to the hand digit number in the picture of the dataset.\n",
    "in order to have a softmax function for classification we need to have for each number of the inputdata a distictive column and its rows input are either 0 or 1.\n",
    "As an input we need a matrix with 10 columns and m rows. `Where m is the number of the examples data = X_train.shape[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The y_train data: [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7]\n",
      "The y_test data: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1]\n",
      "The y_val data: [3 8 6 9 6 4 5 3 8 4 5 2 3 8 4 8 1 5 0 5 9 7 4 1 0 3 0 6 2 9]\n"
     ]
    }
   ],
   "source": [
    "# Visualize the Data\n",
    "print(\"The y_train data:\",y_train_orig[0:30])\n",
    "print(\"The y_test data:\",y_test_orig[0:30])\n",
    "print(\"The y_val data:\",y_val_orig[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train shape: (50000, 10)\n",
      "Y_test shape: (10000, 10)\n",
      "Y_val shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert to one-hot encooding\n",
    "import numpy as np\n",
    "y_train = np.eye(10)[y_train_orig]\n",
    "y_test = np.eye(10)[y_test_orig]\n",
    "y_val = np.eye(10)[y_val_orig]\n",
    "\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))\n",
    "print (\"Y_val shape: \" + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build a Neural Network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals**    \n",
    "- Code a deep (with at least 1 hidden layer) neural network in tensorflow\n",
    "- Fit it on the train dataset, estimate quality on the test dataset\n",
    "- Plot the train loss and test loss as a function of the training iteration number \n",
    "\n",
    "**[bonus score]** If you've already beaten logistic regression with a two-layer net, but enthusiasm still ain't gone, you can try improving the test accuracy even further! The milestones would be 95%/97.5%/98.5% accuracy on the test set.\n",
    "\n",
    "**The model** is *LINEAR -> RELU -> LINEAR -> SOFTMAX*. The SIGMOID output layer has been converted to a SOFTMAX. A SOFTMAX layer generalizes SIGMOID to when there are more than two classes. \n",
    "\n",
    "**Don't forget to shuffle the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 28 * 28 * 1 = 784) # the image we have in a gray scale\n",
    "    n_y -- scalar, number of classes (from 0 to 9, so -> 10)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float64\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float64\"\n",
    "    \"\"\"\n",
    "    # Placeholders for the input data\n",
    "    # input_X = tf.placeholder(...)\n",
    "    # input_y = tf.placeholder(...)\n",
    "    X = tf.placeholder(tf.float64, [ None, n_x],name = \"X\")\n",
    "    Y = tf.placeholder(tf.float64, [None, n_y],name = \"Y\")\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 784)\n",
      "Y_train shape: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "# test the placeholder function\n",
    "X, Y = create_placeholders(784, 10)\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x = 784, num_neurons = 50,num_classes = 10):\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow.\n",
    "    Arguments:\n",
    "    n_x -- size of an image vector (num_px * num_px = 28 * 28 * 1 = 784)\n",
    "    The shapes are:\n",
    "                        W1 : [50, 784]\n",
    "                        b1 : [50, 1]\n",
    "                        W2 : [10, 50]\n",
    "                        b2 : [10, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2\n",
    "    \"\"\"\n",
    "        \n",
    "    weights1 = tf.get_variable(\"weights1\", [n_x,num_neurons], initializer = tf.contrib.layers.xavier_initializer(dtype=tf.float64),dtype=tf.float64) #weights for the 1st layer\n",
    "    bias1 = tf.get_variable(\"bias1\", [num_neurons], initializer = tf.zeros_initializer(dtype=tf.float64),dtype=tf.float64) #biases for the 1st layer\n",
    "    weights2 = tf.get_variable(\"weights2\", [num_neurons,num_classes], initializer = tf.contrib.layers.xavier_initializer(dtype=tf.float64),dtype=tf.float64) #weights for the 2nd layer\n",
    "    bias2 = tf.get_variable(\"bias2\", [num_classes], initializer = tf.zeros_initializer(dtype=tf.float64),dtype=tf.float64) #biases for the 2nd layer\n",
    "\n",
    "    parameters = {\"weights1\": weights1,\n",
    "                  \"bias1\": bias1,\n",
    "                  \"weights2\": weights2,\n",
    "                  \"bias2\": bias2,}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'weights1:0' shape=(784, 50) dtype=float64_ref>\n",
      "b1 = <tf.Variable 'bias1:0' shape=(50, 1) dtype=float64_ref>\n",
      "W2 = <tf.Variable 'weights2:0' shape=(50, 10) dtype=float64_ref>\n",
      "b2 = <tf.Variable 'bias2:0' shape=(1, 10) dtype=float64_ref>\n"
     ]
    }
   ],
   "source": [
    "# Test the parameters function\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"weights1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"bias1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"weights2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"bias2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X_train, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"weights1\", \"bias1\", \"weights2\", \"bias2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    pred_y -- the output of the last (the prediction) LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['weights1']\n",
    "    b1 = parameters['bias1']\n",
    "    W2 = parameters['weights2']\n",
    "    b2 = parameters['bias2']\n",
    "\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(X_train,W1),b1)                      \n",
    "    A1 = tf.nn.relu(Z1)                                   \n",
    "    pred_y = tf.add(tf.matmul(A1,W2),b2)                       \n",
    "    \n",
    "    \n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_y = Tensor(\"Add_1:0\", shape=(50, 10), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# test the forward progagation function\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(X_train.shape[1], 10)\n",
    "    parameters = initialize_parameters()\n",
    "    pred_y = forward_propagation(X, parameters)\n",
    "    print(\"pred_y = \" + str(pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Compute the Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(pred_y, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z2 -- output of forward propagation (output of the last LINEAR unit), of shape (10, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z2\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(pred_y)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred_y, labels = Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# test the cost function\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(784, 10)\n",
    "    parameters = initialize_parameters()\n",
    "    pred_y = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(pred_y, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Backward propagation & parameters update\n",
    "\n",
    "- probably better to use STOCHASTIC gradient descent (minibatch)\n",
    "- sample should probably be shuffled (or use random subsamples on each iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "m = X_train.shape[0]                              # m : number of examples in the train set)\n",
    "n_x = X_train.shape[1]                            # n_x: input size, \n",
    "n_y = y_train.shape[1]                            # n_y : output size\n",
    "train_costs = []                                  # To keep track of the cost\n",
    "test_costs = []\n",
    "\n",
    "num_iterations = 150\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# Create Placeholders of shape (n_x, n_y)\n",
    "X, Y = create_placeholders(n_x, n_y)\n",
    "    \n",
    "# Initialize parameters\n",
    "parameters = initialize_parameters()\n",
    "   \n",
    "# Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "pred_y = forward_propagation(X, parameters)\n",
    " \n",
    "# Cost function: Add cost function to tensorflow graph\n",
    "cost = compute_cost(pred_y, Y)\n",
    "    \n",
    "# Backpropagation: Define the tensorflow optimizer. Using an AdamOptimizer.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 10 iterations: 0.36634869559\n",
      "cost after 20 iterations: 0.297083655429\n",
      "cost after 30 iterations: 0.264567799946\n",
      "cost after 40 iterations: 0.241661708002\n",
      "cost after 50 iterations: 0.222630134644\n",
      "cost after 60 iterations: 0.205748932664\n",
      "cost after 70 iterations: 0.190323736276\n",
      "cost after 80 iterations: 0.176470269573\n",
      "cost after 90 iterations: 0.164373538249\n",
      "cost after 100 iterations: 0.153667278999\n",
      "cost after 110 iterations: 0.143933405089\n",
      "cost after 120 iterations: 0.135259031347\n",
      "cost after 130 iterations: 0.127467408414\n",
      "cost after 140 iterations: 0.120350087471\n",
      "cost after 150 iterations: 0.113859119916\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb05831320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9676\n",
      "Test Accuracy: 0.9593\n",
      "Validation Accuracy: 0.9622\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "     \n",
    "    for iteration in range(num_iterations):\n",
    "        for i in range(0, m, batch_size):\n",
    "            sess.run(optimizer, feed_dict={X:X_train[i:i+batch_size], Y:y_train[i: i+batch_size]})\n",
    "        train_costs.append(sess.run(cost, feed_dict={X:X_train, Y:y_train}))\n",
    "        test_costs.append(sess.run(cost, feed_dict={X:X_test, Y:y_test}))\n",
    "        if iteration%10 == 9:\n",
    "            print(\"cost after \" + str(iteration+1)+ \" iterations: \"+ str(train_costs[-1]))\n",
    "    \n",
    "    iterations = list(range(num_iterations))\n",
    "    plt.plot(iterations, train_costs, label='Train')\n",
    "    plt.plot(iterations, test_costs, label='test')\n",
    "    plt.ylabel('train cost')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate the correct predictions\n",
    "    predict_op = tf.argmax(pred_y, 1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: y_train}))\n",
    "    print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: y_test}))\n",
    "    print (\"Validation Accuracy:\", accuracy.eval({X: X_val, Y: y_val}))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
